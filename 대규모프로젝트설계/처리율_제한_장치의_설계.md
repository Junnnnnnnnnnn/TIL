# 처리율 제한 장치의 설계
> 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다
- 같은 디바이스로 주당 5회 이상 리워드를 요청할 수 없다

## 장점
- DoS 공격에 의해 자원고갈을 방지
- 비용 절감
  - 추가 요청에 대한 처리를 제한하면 서버를 많을 둘 필요가 없다
  - 우선순위가 높은 API에 더 많은 자원을 할당 할 수 있다.
- 서버 과부화를 막는다
  - 봇에서 오는 잘못된 트래픽을 걸러낼 수 있다.

## 요구사항
- 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
- 낮은 응답시간
  - 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주면 안된다.
  - 가능한 한 적은 메모리 사용
  - 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
  - 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
  - 제한장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.

## 설계
> 처리율 제한은 클라리언트 혹은 API 서버에서 처리 할 수 있다 각각의 장단점을 알아보자

- 클라이언트
  - 일반적으로 안정적인 처리율 제한은 힘들다
    - 클라이언트 요청은 위변조가 쉽게 가능하기 때문
- API 서버
  - 서버 제한 장치를 직접 거는 것 보단 미들웨어를 사용해서 걸면 좋다.
- 마이크로 서비스
  - API 게이트웨어이서 구현된다.

> 😊 API 게이트웨이란
>
> - 처리율 제한
> - SSL 종단
> - 사용자 인증
> - IP 허용 목록 (whitelist)
>
> 을 하는 완전 위탁관리형 서비스이다

### 질문 처리율 제한 기능은 어디 두어야 하나

정답은 `없다` 이다<br>
기술스택이나 엔지니어링 인력 우선순위 목표에 따라 달라진다.

### 처리율 제한을 하기 위해 고려해야 할 점
- 기술 스택 점검
  - 프로그래밍 언어, 캐시 서비스등
- 사업에 맞는 처리율 제한 알고리즘
  - 서버측에서 모든 것을 구현한다면 괜찮지만 제3 사업자인 게이트웨이를 사용하기로 했다면 선택지는 제한 될 수 있다.
- 이미 API 게이트웨이를 통해서 whiteList 를 처리 중
  - 처리율 제한은 API 게이트웨이로 구성하는 것이 좋다
- 충분한 인력
  - 충분한 인력이 없다면 상용 API 게이트웨이를 사용하는 것이 바람직

## 처리율 제한 알고리즘
- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

총 다섯가지의 대표 알고리즘이 있다

### 토큰 버킷 알고리즘
> 간단하고 이해도도 높은 편, 인터넷 기업들이 보편적으로 사용중
>
> 아마존, 스트라이프가 이 알고리즘 채택

#### 동작 원리
- 클라이언트의 요청마다 처리할 수 있겠금 토큰을 부여 하는데 이 토큰은 예를들어 초당 - 2개식 생성되며 버킷엔 총 4개을 담을 수 있다.
- 버킷의 토큰이 꽉차있으면 생성되는 토큰은 버려지게 된다.
- 요청이 왔을 때 토큰이 없다면 그 요청은 버려지게 된다.

해당 알고리즘은 두개의 인자를 받는다
- 버킷의 크기
- 초당 토큰의 양
---
**장점**
- 구현이 쉽다
- 메모리 사용 측면에서도 효율적이다
- 짧은 시간에 집중되는 트래픽 처리 가능

**단점**
- 두 개 인자를 가지고 있기 때문에 적절하게 튜닝을 가지는 것이 까다롭다

### 누출 버킷 알고리즘
> 해당 알고리즘은 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있고 FIFO 선입 선출로 주로 큐로 이루어 진다

#### 동작 원리
- 요청을 수행하기 전 큐 버킷에 데이터가 가득 찼는지 확인
- 가득 차 있다면 요청은 버려지게 됨
- 큐는 일정 시간마다 데이터를 꺼내 처리

해당 알고리즘은 두개의 인자를 받는다
- 버킷 크기
  - 큐 사이즈와 같은 값
- 처리율
  - 지정된 시간당 몇개의 항목을 처리할지. 보통 초 단위로 표현

**장점**
- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
- 고정된 처리율을 가지고 있음
  - 안정적 출력이 필요할 때 사용
**단점**
- 단시간에 많은 트래픽이 몰리는 경우
  - 큐에 오래된 요청들이 쌓이고 최신 요청들은 버려지게 됨
- 두개의 인자
  - 적절한 튜닝을 구성하기 힘듬

### 고정 윈도 카운터 알고리즘
#### 동작 원리
- 타임라인을 고정된 간격의 윈도로 나눈다
- 각 윈도마다 카운터를 붙힌다.
- 요청이 접수될 때마다 카운터가 1 증가한다.
- 윈도우에 설정된 임계치를 벗어 나면 다음 요청은 버려진다.

**장점**
- 메모리 효율이 좋다
- 이해하기 쉽다
**단점**
- 윈도 경계부근에서 일시적으로 많은 트래픽을 효과적으로 처리하지 않는다

### 이동 윈도 로깅 알고리즘
> 해당 알고리즘은 고정 윈도 카운터 알고리즘의 단점인 윈도 경계부근의 일시적 트래픽 처리에 대한 문제점을 잡고 있다.

#### 동작 원리
- 요청 타임스탬프를 추적해 Redis 에 sorted set 형식으로 로그 저장
- 새 요청이 왔을 때 만료된 타임스탬프는 제거
- 새 요청을 로그에 추가
- 요청 된 로그(타입스탬프) 의 크기가 같거나 작으면 시스템에 요청 전달

**장점**
- 처리율 제한 메커니즘이 정교하다
**단점**
- 정교한 만큼 다량의 메모리를 사용한다.

## 계략적 알고리즘
> 처리율 제한 알고리즘의 기본아이디어는 단순하다

- 처리율 대상 선정
  - 유저별
  - IP별
  - API 엔드 포인트, 서비스 단위
- 미들웨어 카운팅
  - 카운팅은 디스크 접근으로 하면 속도가 느려지기 때문에 주로 Redis 처리
  - Redis 의 INCR 와 EXPRIE를 사용

## 상세 설계
### 처리율 한도 초과 트래픽의 처리
> 어떤 요청이 한도제한에 걸리면 HTTP 429 응답 (too many request) 를 클라이언트에 보낸다<Br>
> 경우에 따라 버리진 않고 나중에 처리하기 위해 메세지 큐에 보관 할 수도 있다

### 처리율 제한 장치가 사용하는 HTTP 해더
> 클라이언트는 요청이 처리율 제한에 걸리고 있는지를 어떻게 감지 할수 있을까<Br>
> 보통 response header 에 해당 정보를 담는다

| header                  | description                                                         |
| ----------------------- | ------------------------------------------------------------------- |
| X-RateLimit-Remainging  | 윈도 내에 남은 처리 가능 요청의 수                                  |
| X-RateLimit-Limit       | 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수                   |
| X-Ratelimit-Retry-After | 한도 제한에 걸리지 않으려면 몇초뒤에 요청을 다시 보내야 하는지 알림 |

그림 4-13을 참고

### 분산 환경에서의 처리율 제한 장치의 구현
**경쟁 조건**
>두개의 서버에서 하나의 레디스의 처리율 제한 처리를 할때에 문재점은 원자성을 보장할 수 없다는 점이다<br>
>이것을 해결하기 위해선 보통 Lock 기법을 많이 사용하는데 Lock은 시스템의 성능을 떨어뜨린다
>
>이때 사용할 수 있는 것이 루아 스크립트리고 다른 하나는 정렬집합이다.

**동기화 이슈**

처리율 제한 미드웨어는 각각의 Redis 저장장치를 바라보는 것이 아닌 하나의 제한장치를 바라보고 처리 한다